# Desafio Digesto
## (Introdução)
(breve descrição do problema)
## (Conceito inicial)
(requisitar pagina, varrer estrutura pra encontro de dados via regex, tratamento de dados, criação de saidas)
(feito em Python 3.x)
(possível tratamento de erros nestas etapas)
## (Etapa 1)
(import requests, breve descrição)
(requisicao pagina: request.get)
(varrer estrutura: lxml)
(encontrando dados: xpath)
(copia de xPath via Chrome)
(indentificação de indexes e construção de xpaths especificos)
(extracao de dados)
	(atencao aos conteudos em <strong> e whitespaces (\n\t\t))
	(tratamento de dados)
	(duas xpath, concatenação de listas)
	(dispensando IvP6 por agora)
(impressão de dados)
	(impressão em tabela)
### (Reflexões)
(tempo de execução: ~ 44s)
	(request ocupa a maior parte do processo)
	(estudar como reduz o tempo da request)
(extração em duas listas para storage e price)
	(estudar possível redução de passos)
(IvP6 dispensado)
	(atenção a específidades de entradas)
	(estudo de tratamentos para casos como este)
## (Etapa 2)
(implementação de salvar em JSON)
(leitura de sys.args)
	(import sys)
	(variáveis boolean para propriedades de impressão)
	(identificação e tratamento de commandos)
(adição de variável a método de impressão)
(impressão em JSON)
	(import json)
	(escrever arquivo com json.dump)
### (Reflexões)
(formatação)
	(array de arrays neste caso)
	(tratamento de criação de objetos possível com função)
(especificação de local para salvar o arquivo)
	(possível recebimento por argv)
## (Etapa 3)
(implementação de salvar em CSV)
(adiçao da variavel de sys.argv)
(impressão em CSV)
	(import csv)
	(escrever arquivo via writerow)
	(para cada linha, para cada variavel)
### (Reflexões)
(retorno a questão da especificação de local para salvar o arquivo)
	(possível recebimento por argv)
## (Etapa 4)
(nova pagina para extraçao)
	(processo similar de criaçao ao site anterior)
### (Reflexões)
(possíveis opções de escolha de sites)
	(mandando dominio por sys.argv, por exemplo)
(maior facilidade com xpath)
	(relação com a estrutura do html)
(request mais rapido em DigitalOcean)
	(atraso é algo em relação a pagina da Vultr)
## (Aprimoramentos)
(adição --digitalocean e --vultr)
	(websites_default)
(verificação de situação sem print)
	(print_default)
(conserto da request demorada)
	(analise da situação)
	(request_test.py)
	(encoding está correto)
	(urllib.error.HTTPError: HTTP Error 403: Forbidden)
	(dobro do tempo com especificação de agent)
	(url https://www.vultr.com/products/cloud-compute/ não interfere)
	(faster_than_requests)
		(error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.21.27702\\bin\\HostX86\\x64\\cl.exe' failed with exit status 2)
(modularização do código)
	(request/fromstring)
	(extração)
		(extractData)
	(prints)
		(metodos de print)